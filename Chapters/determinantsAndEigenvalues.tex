\section{Lecture 13: September 21, 2022}

    \subsection{Defining the Determinant}

        Consider the following theorems and definitions.
        \begin{theorem}{\Stop\,\,The Determinant Determines the Area in \(\mathbb{R}^2\)}{areadet}

            Consider \(\vec{x}=[x_1,x_2]\) and \(\vec{y}=[y_1,y_2]\). If we form
            \begin{equation*}
                A=\begin{bmatrix}
                    x_1 & x_2 \\
                    y_1 & y_2 
                \end{bmatrix},
            \end{equation*}
            \begin{equation*}
                |\det A| = ||\vec{x}\times\vec{y}||.
            \end{equation*}
            That is, \(|\det A|\) provides the area of the parallelogram determined by \(\vec{x}\) and \(\vec{y}\).
            
        \end{theorem}
        \begin{theorem}{\Stop\,\,The Determinant Determines the Volume in \(\mathbb{R}^3\)}{voldet}

            Consider \(\vec{x}=[x_1,x_2,x_3]\), \(\vec{y}=[y_1,y_2,y_3]\), and \(\vec{z}=[z_1,z_2,z_3]\).
            If we form
            \begin{equation*}
                A=\begin{bmatrix}
                    x_1 & x_2 & x_3 \\
                    y_1 & y_2 & y_3 \\
                    z_1 & z_2 & z_3
                \end{bmatrix},
            \end{equation*}
            \begin{equation*}
                |\det A| = \vec{x}\cdot(\vec{y}\times\vec{z}).
            \end{equation*}
            That is, \(|\det A|\) provides the volume of the parallelepiped determined by \(\vec{x}\), \(\vec{y}\), and \(\vec{z}\).
            
        \end{theorem}
        \begin{definition}{\Stop\,\,The \((i,j)\) Submatrix}{submatrix}

            Suppose \(A\in\mathcal{M}_{nn}\). The \((i,j)\) submatrix of \(A\) is the \((n-1)\times(n-1)\) matrix obtained by removing the \(i\)th row and the \(j\)th column. We denote this by \(A_{(i,j)}\) 
            
        \end{definition}
        \begin{definition}{\Stop\,\,The \((i,j)\) Minor}{minor}

            Suppose \(A\in\mathcal{M}_{nn}\). The \((i,j)\) minor of \(A\) is the determinant of the \((i,j)\) submatrix of \(A\).
            
        \end{definition}
        \begin{definition}{\Stop\,\,The \((i,j)\) Cofactor}{cofactor}

            Suppose \(A\in\mathcal{M}_{nn}\). The \((i,j)\) cofactor of \(A\) is
            \begin{equation*}
                A_{ij}=(-1)^{i+j}\det (A_{(i,j)}).
            \end{equation*}
            
        \end{definition}
        \begin{definition}{\Stop\,\,The Determinant}{det}
            Suppose \(A\in\mathcal{M}_{nn}\). Then,
            \begin{enumerate}
                \item If \(n=1\), and \(A=\begin{bmatrix} a_{11} \end{bmatrix}\), \(\det A = a_{11}\).
                \item If \(n=2\), and \(A=\begin{bmatrix} a_{11} & a_{12} \\ a_{21} & a_{22} \end{bmatrix}\), \(\det A = a_{11}a_{22}-a_{12}a_{21}\).
                \item If \(n>2\), and \(A=\begin{bmatrix} a_{11} & \cdots & a_{1n} \\ \vdots & \ddots & \vdots \\ a_{n1} & \cdots & a_{nn} \end{bmatrix}\), \(\det A = (a_{11}A_{11}+\cdots+a_{1n}A_{1n})+\cdots+(a_{n1}A_{n1}+\cdots+a_{nn}A_{nn})\).
            \end{enumerate}
        \end{definition}
        \pagebreak
        \vphantom
        \\
        \\
        For fun, consider the following Python 3 implementation of computing the determinant of any \(n\times n\) matrix.
        \lstinputlisting[language=Python]{Graphics/matrixdet.py}
        
        \pagebreak

\section{Lecture 14: September 23, 2022}

    \subsection{Determinants of Upper Triangular Matrices}

        Consider the following theorems.
        \begin{theorem}{\Stop\,\,The Determinant of an Upper Triangular Matrix}{uppertriangulardet}

            If \(A\in\mathcal{M}_{nn}\) is upper triangular, 
            \begin{equation*}
                \det A = a_{11} a_{22} \cdots a_{nn}.
            \end{equation*}
            Recall that \(A\) is upper triangular if and only if all elements below the main diagonal are zero.
            \begin{proof}
                We proceed by induction on \(n\). For \(n=1\), \(A=\begin{bmatrix} a_{11} \end{bmatrix}\), so \(\det A = a_{11}\). Suppose for all \(k\in\mathbb{N}\), and some upper triangular \(A\in\mathcal{M}_{kk}\),
                \begin{equation*}
                    a_{11} a_{22} \cdots a_{kk}.
                \end{equation*}
                Consider 
                \begin{equation*}
                    B=\begin{bmatrix}
                        b_{11} & \cdots & b_{1(k+1)} \\
                        \vdots & \ddots & \vdots \\
                        0 & \cdots & b_{(k+1)(k+1)}
                    \end{bmatrix}.
                \end{equation*}
                Then, we compute \(\det B\) using the last row as our ``first row.''
                \begin{align*}
                    \det B &= (-1)^{1+1}b_{11}\det\begin{bmatrix} b_{22} & b_{23} & \cdots & a_{2(k+1)} \\ 0 & b_{33} & \cdots & b_{3(k+1)} \\ \vdots & \vdots & \vdots & \vdots \\ 0 & 0 & 0 & b_{(k+1)(k+1)} \end{bmatrix} \\
                    &= b_{11}\underbrace{b_{22}\cdots b_{(k+1)(k+1)}}_{\text{By the inductive hypothesis.}}.
                    %\begin{comment}\det B&= 0+\cdots+0+a_{(k+1)(k+1)}(-1)^{(k+1)+(k+1)}\det B_{(k+1),(k+!)} \\ &=a_{(k+1)(k+1)}(-1)^{2(k+1)}\det A.\end{comment}
                \end{align*}
                This is precisely the stipulation of the theorem when \(n=k+1\).
            \end{proof}

        \end{theorem}
        \pagebreak
        \begin{theorem}{\Stop\,\,Determinants and Row Operations}{detrowops}

            Suppose \(A\in\mathcal{M}_{nn}\) and let \(R\) be a row operation. Then,
            \begin{enumerate}
                \item If \(R\) is \(c\langle i\rangle\to\langle i \rangle\) for some \(c\in\mathbb{R}\), 
                \begin{equation*}
                    \det R(A) = c\det A.
                \end{equation*}
                Note that if \(c=0\), \(R\) is not a valid row operation.
                \item If \(R\) is \(c\langle i\rangle+\langle j \rangle\to\langle j \rangle\) for some \(c\in\mathbb{R}\),
                \begin{equation*}
                    \det R(A) = \det A.
                \end{equation*}
                Note that if \(c=0\), \(R\) is not a valid row operation.
                \item If \(R\) is \(\langle i \rangle\leftrightarrow\langle j \rangle\),
                \begin{equation*}
                    \det R(A) = -\det A.
                \end{equation*}
            \end{enumerate}
            \vphantom
            \\
            \\
            Note that if \(\det A\neq 0\) and \(R\) is a row operation, \(\det R(A)\neq 0\).
        \end{theorem}
        \vphantom
        \\
        \\
        We can use Theorem \ref{thm:detrowops} in conjunction with row operations to compute the determinant of a matrix easily. We simply use row operations to create an upper triangular matrix, while keeping track of how the determinant changes. We then apply Theorem \ref{thm:uppertriangulardet}. Consider the following examples.
        \begin{example}{\Difficulty\,\Difficulty\,\,Computing a Determinant by Row Reduction}{compdetrowred}
            
            Compute \(\det\begin{bmatrix} 1 & 1 & 1 \\ 2 & 3 & -2 \\ 4 & 9 & 4 \end{bmatrix}\).
            \\
            \\
            Let 
            \begin{equation*}
                A_0=\begin{bmatrix} 1 & 1 & 1 \\ 2 & 3 & -2 \\ 4 & 9 & 4 \end{bmatrix}.
            \end{equation*}
            Consider the following table.
            \begin{center}
                \begin{tabular}{||c|c|c||}
                    \hline
                    Row Operation & Resultant Matrix & Effect on the Determinant \\
                    \hline
                    \hline
                    \(-2\langle1\rangle+\langle2\rangle\to\langle2\rangle\) & \(A_1=\begin{bmatrix} 1 & 1 & 1 \\ 0 & 1 & -4 \\ 4 & 9 & 4 \end{bmatrix}\) & \(\det A_1=\det A_0\) \\
                    \hline
                    \(-4\langle1\rangle+\langle3\rangle\to\langle3\rangle\) & \(A_2=\begin{bmatrix} 1 & 1 & 1 \\ 0 & 1 & -4 \\ 0 & 5 & 0 \end{bmatrix}\) & \(\det A_2=\det A_1\) \\
                    \hline
                    \(-5\langle2\rangle+\langle3\rangle\to\langle3\rangle\) & \(A_3=\begin{bmatrix} 1 & 1 & 1 \\ 0 & 1 & -4 \\ 0 & 0 & 20 \end{bmatrix}\) & \(\det A_3=\det A_2\) \\
                    \hline
                \end{tabular}
            \end{center}
            \vphantom
            \\
            \\
            Thus, \(\det A_0=20\).

        \end{example}
        \pagebreak
        \begin{example}{\Difficulty\,\Difficulty\,\,Computing a Determinant by Row Reduction}{compdetrowred}
            
            Compute \(\det\begin{bmatrix} 0 & -14 & -8 \\ 1 & 3 & 2 \\ -2 & 0 & 6 \end{bmatrix}\).
            \\
            \\
            Let 
            \begin{equation*}
                A_0=\begin{bmatrix} 0 & -14 & -8 \\ 1 & 3 & 2 \\ -2 & 0 & 6 \end{bmatrix}.
            \end{equation*}
            Consider the following table.
            \begin{center}
                \begin{tabular}{||c|c|c||}
                    \hline
                    Row Operation & Resultant Matrix & Effect on the Determinant \\
                    \hline
                    \hline
                    \(\langle2\rangle\leftrightarrow\langle1\rangle\) & \(A_1=\begin{bmatrix} 1 & 3 & 2 \\ 0 & -14 & -8 \\ -2 & 0 & 6 \end{bmatrix}\) & \(\det A_1=-\det A_0\) \\
                    \hline
                    \(2\langle1\rangle+\langle3\rangle\to\langle3\rangle\) & \(A_2=\begin{bmatrix} 1 & 3 & 2 \\ 0 & -14 & -8 \\ 0 & 6 & 10 \end{bmatrix}\) & \(\det A_2=\det A_1\) \\
                    \hline
                    \(-\frac{1}{14}\langle2\rangle\to\langle2\rangle\) & \(A_3=\begin{bmatrix} 1 & 3 & 2 \\ 0 & 1 & \frac{4}{7} \\ 0 & 6 & 10 \end{bmatrix}\) & \(\det A_3=-\frac{1}{14}\det A_2\) \\
                    \hline
                    \(-6\langle2\rangle+\langle3\rangle\to\langle3\rangle\) & \(A_3=\begin{bmatrix} 1 & 3 & 2 \\ 0 & 1 & \frac{4}{7} \\ 0 & 0 & \frac{46}{7} \end{bmatrix}\) & \(\det A_4=\det A_3\) \\
                    \hline
                \end{tabular}
            \end{center}
            \vphantom
            \\
            \\
            Thus, \(\det A_0=\frac{46}{7}(-14)(-1)=92\).

        \end{example}
        \vphantom
        \\
        \\
        Consider the following theorem.
        \begin{theorem}{\Stop\,\,Inverses and Determinants}{invdet}
            
            Suppose that \(A\in\mathcal{M}_{nn}\). Then, \(A\) is nonsingular if and only if \(\det A \neq 0\).
            \begin{proof}
                If \(A\) is nonsingular, we can row reduce \(A\) to produce \(I_n\). Since \(\det I_n\neq 0\), by Theorem \ref{thm:detrowops}, \(\det A\neq 0\). If \(\det A\neq 0\), we form the system \([A|B]\) and reduce it to \([C|D]\). We know that \(\det C\neq 0\). Because \(C\) is in reduced row echelon form, and square since \(A\) is square, it is upper triangular. That means all main diagonal entries are nonzero, meaning they are all \(1\). Meaning \(C=I_n\). This means we were able to row reduce \(A\) to \(I_n\), so \(A\) is nonsingular.
            \end{proof}
            
        \end{theorem}
        \vphantom
        \\
        \\
        Consider the following table summarizing various results about singularity, determinants, rank, existence and uniqueness of linear systems, and row equivalence. Statements in each column are equivalent.
        \begin{center}
            \begin{tabular}{c|c}
                \hline
                \(A\in\mathcal{M}_{nn}\) is Nonsingular & \(A\in\mathcal{M}_{nn}\) is Singular \\
                \hline
                \(\rank A = n\) & \(\rank A < n\) \\
                \(\det A \neq 0\) & \(\det A = 0\) \\
                \(A\) is row equivalent to \(I_n\). & \(A\) is not row equivalent to \(I_n\). \\
                \(AX=0\) has only the trivial solution for \(X\). & \(AX=0\) has a nontrivial solution for \(X\). \\
                \(AX=B\) has a unique solution for \(X\), and \(X=A^{-1}B\). & \(AX=B\) does not have a unique solution. \\
                \hline
            \end{tabular}
        \end{center}

\pagebreak

\section{Lecture 15: September 26, 2022}

    \subsection{Further Properties of Determinants}

        \begin{theorem}{\Stop\,\,Properties of Determinants}{detprop}

            Suppose \(A,B\in\mathcal{M}_{nn}\). Then,
            \begin{enumerate}
                \item \(\det (AB) = \det A\det B\).
                \begin{proof}
                    If \(A\) or \(B\) is singular, \(\det A\det B=0\). For now, let \(B\) be singular. We don't make any assumptions about \(A\), for now. Sine \(B\) is singular, there exists some \(X\neq0\) such that \(BX=0\). We consider \((AB)X=A(BX)=A(0)=0\). Thus, \(X\) is a nontrivial solution to the homogeneous equation associated with \(AB\). Thus \(AB\) is singular and \(\det (AB) = 0 = \det A\det B\). Now, suppose that \(A\) is singular and \(B\) is nonsingular. There exists a nontrivial solution for \(Y\) in the system \(AY=0\). Since \(B\) is nonsingular, \(B^{-1}\) exists. We define \(X=B^{-1}Y\) where \(X\neq0\). Then \(ABX=AB(B^{-1}Y)=AY=0\). Thus, \(ABX\) and \(X\neq 0\) implies that \(AB\) is singular, so \(\det (AB)=0\). Now, we consider the case where \(A\) and \(B\) are both nonsingular. There exists row operations \(R_1,\ldots,R_k\) such that \(A=R_1(\ldots(R_k(I_n)\ldots))\) and 
                    \begin{align*}
                        \det (AB)&=\det(R_1(\ldots(R_k(I_n)\ldots))B) \\
                        &=c_1\cdots c_k\det (I_nB) \\
                        &=c_1\cdots c_k\det B \\
                        &=c_1\cdots c_k \det I_n\det B \\
                        &=\det(R_1(\ldots(R_k(I_n)\ldots)))\det B \\
                        &=\det A\det B,
                    \end{align*}
                    hence proving the proposition.
                \end{proof}
                \item \(\det (A^T) = \det A\).
                \item \(\underbrace{\det (A^{-1}) = \frac{1}{\det A}}_{\text{Suppose that \(A\) is nonsingular.}}\).
                \begin{proof}
                    We know that \(A\) is nonsingular. We have \(\det I_n=\det(AA^{-1})=\det A\det (A^{-1})=1\). By simple algebra, \(\det (A^{-1})=\frac{1}{\det A}\).
                \end{proof}
            \end{enumerate}
            
        \end{theorem}

    \pagebreak

    \subsection{Eigenvectors, Eigenvalues, and Diagonalization}

        Consider the following definition.

        \begin{definition}{\Stop\,\,Similarity}{sim}

            Suppose \(A,B\in\mathcal{M}_{nn}\). Then, \(A\) and \(B\) are similar if and only if there exists nonsingular \(P\) such that
            \begin{equation*}
                A=PBP^{-1}.
            \end{equation*}
            
        \end{definition}
        \begin{definition}{\Stop\,\,Diagonalizability}{diagonalizability}

            The matrix \(A\in\mathcal{M}_{nn}\) is diagonalizable if \(A\) is similar to a diagonal matrix.
            
        \end{definition}
        \begin{definition}{\Stop\,\,Eigenvalues and Eigenvectors}{eigenvaluesandvectors}

            For \(A\in\mathcal{M}_{nn}\), \(\lambda\in\mathbb{R}\) is an eigenvalue of \(A\) if and only if there exists \(X\neq0\) such that
            \begin{equation*}
                AX=\lambda X.
            \end{equation*}
            If \(\lambda\) is an eigenvalue of \(A\), \(X\) is an eigenvector of \(A\) with eigenvalue \(\lambda\).

        \end{definition}