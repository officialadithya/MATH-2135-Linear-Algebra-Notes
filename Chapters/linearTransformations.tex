\section{Lecture 30: November 4, 2022}

    \subsection{An Introduction to Linear Transformations}

        Before proceeding into linear transformations, for a review of functions and associated terminology, consult Appendix \ref{appendix:b}. Consider the following definition.
        \begin{definition}{\Stop\,\,Linear Transformations}{lineartransformation}

            Let \(V\) and \(W\) be vector spaces. Let \(F:V\to W\) be a function. Then, \(F\) is a linear transformation if and only if both the following conditions hold:
            \begin{enumerate}
                \item \(\forall \vec{v}_1,\vec{v}_2\in V, F(\vec{v}_1+\vec{v}_2)=F(\vec{v}_1)+F(\vec{v}_2)\).
                \item \(\forall c\in\mathbb{F},\forall\vec{v}\in V, F(c\vec{v})=cF(\vec{v})\).
            \end{enumerate}
            
        \end{definition}
        \vphantom
        \\
        \\
        We remark that a linear transformation ``preserves'' the operations that give structure to the vector spaces involved: vector addition and scalar multiplication.
        \pagebreak
        \\
        \\
        Consider the following examples.
        \begin{example}{\Difficulty\,\Difficulty\,\,Is it a Linear Transformation? 1}{lintrans1}

            Let \(F:\mathcal{M}_{mn}\to \mathcal{M}_{nm}\) where \(F(A)=A^T\). Is \(F\) a linear transformation?
            \\
            \\
            For matrices \(A_1,A_2\in\mathcal{M}_{mn}\) and scalar \(c\in\mathbb{R}\), we have
            \begin{align*}
                F(A_1+A_2)&=(A_1+A_2)^T \\
                &=A_1^T+A_2^T \\
                &=F(A_1)+F(A_2)
            \end{align*}
            and
            \begin{align*}
                F(cA_1)&=(cA_1)^T \\
                &=cA_1^T \\
                &=cF(A_1).
            \end{align*}
            Thus, \(F\) is a linear transformation.
            
        \end{example}
        \begin{example}{\Difficulty\,\Difficulty\,\,Is it a Linear Transformation? 2}{lintrans2}

            Let \(F:\mathcal{P}_n\to\mathcal{P}_{n-1}\) where \(F(\vec{p})=\vec{p}'\), the derivative of \(\vec{p}\). Is \(F\) a linear transformation?
            \\
            \\
            For \(\vec{p}_1,\vec{p}_2\in \mathcal{P}_n\), we know, from Calculus, that the derivative of a sum is the sum of the derivatives, so
            \begin{align*}
                F(\vec{p}_1+\vec{p_2})&=(\vec{p}_1+\vec{p}_2)' \\
                &=\vec{p}_1'+\vec{p}_2' \\
                &=F(\vec{p}_1)+F(\vec{p}_2).
            \end{align*}
            For \(c\in\mathbb{R}\), the constant multiple rule, from Calculus, tells us that
            \begin{align*}
                F(c\vec{p}_1)&=(c\vec{p}_1)' \\
                &=c\vec{p_1}' \\
                &=cF(\vec{p_1}).
            \end{align*}
            Thus, \(F\) is a linear transformation.
        \end{example}
        \pagebreak
        \begin{example}{\Difficulty\,\Difficulty\,\,Is it a Linear Transformation? 3}{lintrans3}

            Let \(F:\mathcal{P}_{n}\to W\) where \(W=\Span\left\{\frac{1}{s},\ldots,\frac{1}{s^{n+1}}\right\}\) and
            \begin{align*}
                F(\vec{p})&=\laplace{\vec{p}(t)}(s) \\
                &=\int_0^\infty e^{-st}\vec{p}(t)\dd t.
            \end{align*}
            Is \(F\) a linear transformation?
            \\
            \\
            For \(\vec{p}_1(t),\vec{p}_2(t)\in\mathcal{P}_n\), we have
            \begin{align*}
                F(\vec{p}_1(t)+\vec{p}_2(t))&=\int_0^\infty e^{-st}(\vec{p}_1(t)+\vec{p}_2(t))\dd t \\
                &=\int_0^\infty e^{-st}\vec{p}_1(t)+e^{-st}\vec{p}_2(t)\dd t \\
                &=\int_0^\infty e^{-st}\vec{p}_1(t)\dd t+\int_0^\infty e^{-st}\vec{p}_2(t)\dd t \\
                &=F(\vec{p}_1(t))+F(\vec{p}_2(t)).
            \end{align*}
            For \(c\in\mathbb{R}\), we have 
            \begin{align*}
                F(c\vec{p}_1(t))&=\int_0^\infty ce^{-st}\vec{p}_1(t)\dd t \\
                &=c\int_0^\infty e^{-st}\vec{p}_1(t)\dd t \\
                &=cF(\vec{p}_1(t)).
            \end{align*}
            Thus, \(F\) is a linear transformation.
        \end{example}
        \begin{example}{\Difficulty\,\Difficulty\,\,Is it a Linear Transformation? 4}{lintrans4}

            Let \(V\) be a vector space with \(\dim V=n\). Let \(B\) be an ordered basis for \(V\). Then, every \(\vec{v}\in V\) has coordinatization \([\vec{v}]_B\) with respect to \(B\). Consider the function \(F:V\to\mathbb{R}^n\) given by 
            \begin{equation*}
                F(\vec{v})=[\vec{v}]_B.
            \end{equation*}
            Is \(F\) a linear transformation?
            \\
            \\
            By Theorem \ref{thm:propcoords}, \(F\) is a linear transformation.

        \end{example}
        \pagebreak
        \vphantom
        \\
        \\
        We now state some properties of linear transformations.
        \begin{theorem}{\Stop\,\,Properties of Linear Transformations}{proplintrans}

            Let \(V\) and \(W\) be vector spaces, and let \(L:V\to W\) be a linear transformation. Let \(\vec{0}_V\) be the zero vector in \(V\) and \(\vec{0}_W\) be the zero vector in \(W\). Then,
            \begin{enumerate}
                \item \(L(\vec{0}_V)=L(\vec{0}_W)\).
                \begin{proof}
                    Consider \(L(\vec{0}_V)=L(0\vec{0}_V)=0L(\vec{0}_V)=\vec{0}_W\), as desired.
                \end{proof}
                \item \(L(-\vec{v})=-L(\vec{v})\).
                \begin{proof}
                    Consider \(L(-\vec{v})=L(-1\vec{v})=-L(\vec{v})\), as desired.
                \end{proof}
                \item \(L(c_1\vec{v}_1+\cdots+c_n\vec{v}_n)=c_1L(\vec{v}_1)+\cdots+c_nL(\vec{v}_n)\) for \(c_1,\ldots,c_n\in\mathbb{F}\) and \(\vec{v}_1,\ldots,\vec{v}_n\in V\) with \(n\geq2\).
                \begin{proof}
                    We proceed by induction. For the base case when \(n=2\), we have
                    \begin{align*}
                        L(c_1\vec{v}_1+c_2\vec{v}_2)&=L(c_1\vec{v}_1)+L(c_2\vec{v}_2) \\
                        &=c_1L(\vec{v}_1)+c_2L(\vec{v}_2).
                    \end{align*}
                    Then, suppose that for all \(n=k\), 
                    \begin{equation*}
                        L(c_1\vec{v}_1+\cdots+c_k\vec{v}_k)=c_1L(\vec{v}_1)+\cdots+c_kL(\vec{v}_k).
                    \end{equation*}
                    Then, we have
                    \begin{align*}
                        L(c_1\vec{v}_1+\cdots+c_k\vec{v}_k+c_{k+1}v_{k+1})&=c_1L(\vec{v}_1)+\cdots+c_kL(\vec{v}_k)+L(c_{k+1}\vec{v}_{k+1}) \\
                        &=c_1L(\vec{v}_1)+\cdots+c_kL(\vec{v}_k)+c_{k+1}L(\vec{v}_{k+1}),
                    \end{align*}
                    as desired.
                \end{proof}
            \end{enumerate}
            
        \end{theorem}
        \vphantom
        \\
        \\
        We remark that not every function between vector spaces is a linear transformation. To show that some function between vector spaces is not a linear transformation, we must show a counterexample of the conditions in Definition \ref{def:lineartransformation}.
        \pagebreak
        \\
        \\
        We now turn to compositions of linear transformations.
        \begin{theorem}{\Stop\,\,Compositions of Linear Transformations}{compositionslintrans}

            Let \(V_1\), \(V_2\), and \(V_3\) be vector spaces and \(L_1:V_1\to V_2\) and \(L_2:V_2\to V_3\) be linear transformations. Then, \((L_2\circ L_1):V_1\to V_3\) with \((L_2\circ L_1)(\vec{v})=L_2(L_1(\vec{v}))\) is a linear transformation.
            \begin{proof}
                For \(\vec{v}_1,\vec{v}_2\in V_1\), we have
                \begin{align*}
                    (L_2\circ L_1)(\vec{v}_1+\vec{v}_2)&=L_2(L_1(\vec{v}_1+\vec{v}_2)) \\
                    &=L_2(L_1(\vec{v}_1)+L_1(\vec{v}_2)) \\
                    &=L_2(L_1(\vec{v}_1))+L_2(L_1(\vec{v}_2)) \\
                    &=(L_2\circ L_1)(\vec{v}_1)+(L_2\circ L_1)(\vec{v}_2).
                \end{align*}
                Then, for \(c\in\mathbb{F}\), we have
                \begin{align*}
                    (L_2\circ L_1)(c\vec{v}_1)&=L_2(L_1(c\vec{v}_1)) \\
                    &=L_2(cL_1(\vec{v}_1)) \\
                    &=cL_2(L_1(\vec{v}_1)) \\
                    &=c(L_2\circ L_1)(\vec{v}_1),
                \end{align*}
                as desired.
            \end{proof}            
        \end{theorem}
        \vphantom
        \\
        \\
        We now define a special case of linear transformations: linear operators.
        \begin{definition}{\Stop\,\,Linear Operators}{linearoperator}

            Let \(V\) be a vector space. A linear operator on \(V\) is a linear transformation whose domain and codomain are both \(V\).
            
        \end{definition}
        \pagebreak
        \vphantom
        \\
        \\
        We end this section with a result about subspaces and linear transformations.
        \begin{theorem}{\Stop\,\,Linear Transformations and Subspaces}{lintranssubspc}

            Let \(L:V\to W\) be a linear transformation. Then,
            \begin{enumerate}
                \item If \(V'\) is a subspace of \(V\), \(L(V')=\{L(\vec{v}):\vec{v}\in V'\}\), the image of \(V'\) in \(W\), is a subspace of \(W\). That is, the range of \(L\) is a subspace of \(W\).
                \item If \(W'\) is subspace of \(W\), then \(L^{-1}(W')=\{\vec{v}\in V:L(\vec{v})\in W'\}\), the pre-image of \(W'\) in \(V\), is a subspace of \(V\).
                \begin{proof}
                    We know \(\vec{0}_W\in W'\) since \(W'\) is a subspace. Then, \(\vec{0}_V\in L^{-1}(W')\) since \(L(\vec{0}_V)=\vec{0}_W\in W'\). Next, we take \(\vec{v}_1,\vec{v}_2\in L^{-1}(W')\), hence \(L(\vec{v}_1),L(\vec{v}_2)\in W'\). Since \(W'\) is a subspace,
                    \begin{equation*}
                        L(\vec{v}_1)+L(\vec{v}_2)\in W.
                    \end{equation*}
                    Because \(L\) is linear, \(L(\vec{v}_1)+L(\vec{v}_2)=L(\vec{v}_1+\vec{v}_2)\). Thus, \(L(\vec{v}_1+\vec{v}_2)\in W'\). That is, \(\vec{v}_1+\vec{v}_2\in L^{-1}(W')\). Finally, for \(c\in\mathbb{F}\), we have \(L(c\vec{v}_1)=cL(\vec{v}_1)\). Since \(W'\) is a subspace and \(L(\vec{v}_1)\in W'\), we have that \(cL(\vec{v}_1)\in W'\). Thus, \(L(c\vec{v}_1)\in W'\) , so \(c\vec{v}_1\in L^{-1}(W')\).
                \end{proof}
            \end{enumerate}
            
        \end{theorem}
        \pagebreak
\section{Lecture 31: November 7, 2022}

    \subsection{Linear Transformations and Bases}

        We begin with an important theorem.
        \begin{theorem}{\Stop\,\,Linear Transformations and Bases}{lineartransformationsbases}

            Let \(B=\{\vec{v}_1,\ldots,\vec{v}_n\}\) be a basis for a vector space \(V\). Let \(W\) be a vector space with \(\vec{w}_1,\ldots,\vec{w}_n\in W\). Then, there exists a unique linear transformation \(L:V\to W\) such that
            \begin{equation*}
                L(\vec{v}_1)=\vec{w}_1,\ldots,L(\vec{v}_n)=\vec{w}_n.
            \end{equation*}
            \begin{proof}
                Let \(L:V\to W\) be a linear transformation with
                \begin{equation*}
                    (c_1\vec{v}_1+\cdots+c_n\vec{v}_n)\mapsto(c_1\vec{w}_1+\cdots+c_n\vec{w}_n)
                \end{equation*}
                for scalars \(c_1,\ldots,c_n\). We note that \(L\) is well-defined because \(c_1,\ldots,c_n\) are unique. We will show \(L\) is linear by considering
                \begin{align*}
                    L(\vec{v}+\vec{v}')&=L(c_1\vec{v}_1+\cdots+c_n\vec{v}_n+c_1'\vec{v}_1+\cdots+c_n'\vec{v}_n) \\
                    &=L((c_1+c_1')\vec{v}_1+\cdots+(c_n+c_n')\vec{v}_n) \\
                    &=(c_1+c_1')\vec{w}_1+\cdots+(c_n+c_n')\vec{w}_n \\
                    &=c_1\vec{w}_1+c_1'\vec{w}_1+\cdots+c_n\vec{w}_n+c_2'\vec{w}_n \\
                    &=c_1\vec{w}_1+\cdots+c_n\vec{w}_n+c_1'\vec{w}_1+\cdots+c_n'\vec{w}_n \\
                    &=L(\vec{v})+L(\vec{v}').
                \end{align*}
                We now consider
                \begin{align*}
                    L(c\vec{v})&=L(cc_1\vec{v}_1+\cdots+cc_n\vec{v}_n) \\
                    &=cc_1\vec{w}_1+\cdots+cc_n\vec{w}_n \\
                    &=c(c_1\vec{w}_1+\cdots+c_n\vec{w}_n) \\
                    &=cL(\vec{v}).
                \end{align*}
                Now, we will show that \(L(\vec{v}_i)=\vec{w}_i\). We have that
                \begin{align*}
                    L(\vec{v}_i)&=L(0\vec{v}_1+\cdots+1\vec{v}_i+\cdots+0\vec{v}_n) \\
                    &=\vec{w}_i.
                \end{align*}
                We have shown existence, and now, will show uniqueness. Suppose \(R:V\to W\) is a linear transformation and \(R(\vec{v}_i)=\vec{w}_i\) for \(1\leq i\leq n, i\in \mathbb{N}\). We will show that \(R\) and \(L\) equal. Let \(\vec{v}\in V\). Then,
                \begin{align*}
                    R(\vec{v})&=R(c_1\vec{v}_1+\cdots+c_n\vec{v}_n) \\
                    &=c_1R(\vec{v}_1)+\cdots+c_nR(\vec{v}_n) \\
                    &=c_1\vec{w}_1+\cdots+c_n\vec{w}_n \\
                    &=L(\vec{v}).
                \end{align*}
                Thus, \(L\) and \(R\) are the same transformation.
            \end{proof}
            
            
        \end{theorem}

\pagebreak

\section{Lecture 32: November 9, 2022}

    \subsection{The Matrix of a Linear Transformations}

        Consider the following theorem. 
        \begin{theorem}{\Stop\,\,Matrices and Linear Transformations}{matlintrans}
            
            Let \(V\) and \(W\) be vector spaces. Let \(B_V=(\vec{v}_1,\ldots,\vec{v}_n)\) be an ordered basis for \(V\) and let \(B_W=(\vec{w}_1,\ldots,\vec{w}_n)\) be an ordered basis for \(W\). Then, given \(L:V\to W\), there exists a unique matrix \(A_{BC}\in\mathcal{M}_{nn}\) such that
            \begin{equation*}
                A_{B_VB_W}[\vec{v}]_{B_V}=[L(\vec{v})]_{B_W}.
            \end{equation*}

        \end{theorem}
        \vphantom
        \\
        \\
        Consider the following example.
        \begin{example}{\Difficulty\,\Difficulty\,\,Finding a Matrix for a Linear Transformation}{findmat}
            
            Consider
            \begin{equation*}
                L:\mathbb{R}^2\to\mathbb{R}^2, \begin{bmatrix} x \\ y \end{bmatrix} \mapsto \begin{bmatrix} x+y \\ x \end{bmatrix}.
            \end{equation*}
            Find the linear transformation for \(L\).
            \\
            \\
            Consider
            \begin{align*}
                A_{\left(\begin{bmatrix} 0 \\ 1 \end{bmatrix}, \begin{bmatrix} 1 \\ 0 \end{bmatrix}\right),\left(\begin{bmatrix} 1 \\ 0 \end{bmatrix},\begin{bmatrix} 0 \\ 1 \end{bmatrix}\right)}&=\begin{bmatrix} L\left(\begin{bmatrix} 1 \\ 0 \end{bmatrix}\right) & L\left(\begin{bmatrix} 0 \\ 1 \end{bmatrix}\right) \end{bmatrix} \\
                &=\begin{bmatrix}
                    1 & 1 \\
                    1 & 0
                \end{bmatrix}.
            \end{align*}
            Notice
            \begin{equation*}
                \begin{bmatrix}
                    1 & 1 \\
                    1 & 0
                \end{bmatrix}\begin{bmatrix} x \\ y \end{bmatrix}=\begin{bmatrix} x+y \\ x \end{bmatrix}.
            \end{equation*}
        \end{example}
        \pagebreak
        \vphantom
        \\
        \\
        Consider the following theorem.
        \begin{theorem}{\Stop\,\,Matrices for Linear Transformation, Considering Different Bases}{matricesconsdiffbases}
            Let \(V\) and \(W\) be vector spaces with \(B\) and \(D\) be bases for \(V\) and \(C\) and \(E\) be bases for \(W\). We suppose \(\dim V = n\) and \(\dim W = m\) and \(L:V\to W\) is a linear transformation. Then,
            \begin{equation*}
                QA_{BC}P^{-1}=A_{DE}
            \end{equation*}
            where \(P\) is the transition matrix from \(B\) to \(D\) and \(Q\) is the transition matrix from \(C\) to \(E\).
            \begin{proof}
                Recall that
                \begin{enumerate}
                    \item \(P[\vec{v}]_B=[\vec{v}]_D\).
                    \item \(P^{-1}[\vec{v}]_D=[\vec{v}]_B\).
                    \item \(Q[\vec{v}]_C=[\vec{v}]_E\).
                    \item \(A_{BC}[\vec{v}]_B=[L(\vec{v})]_C\).
                    \item \(A_{DE}[\vec{v}]_D=[L(\vec{v})]_E\).
                \end{enumerate}
                \vphantom
                \\
                \\
                We now consider
                \begin{align*}
                    (QA_{BC}P^{-1})[\vec{v}]_D&=(QA_{BC})(P^{-1}[\vec{v}]_D) \\
                    &=(QA_{BC})[\vec{v}]_B \\
                    &=Q(A_{BC}[\vec{v}]_B) \\
                    &=Q[L\vec{v}]_C \\
                    &=[L\vec{v}]_E \\
                    &=A_{DE},
                \end{align*}
                as desired.
            \end{proof}
        \end{theorem}
        \vphantom
        \\
        \\
        As an important special case, we revisit and consider similar matrices.
        \begin{theorem}{\Stop\,\,Similar Matrices and Linear Transformations}{simmatlintrans}

            Let \(V\) and \(W\) be vector spaces with \(V=W\). Let \(B\) and \(D\) be bases for \(V\) and \(C\) and \(E\) be bases for \(W\), with \(B=C\) and \(D=E\). Then, by Theorem \ref{thm:matricesconsdiffbases}.
            \begin{equation*}
                PA_{BB}P^{-1}=A_{DD}.
            \end{equation*}
            Thus, \(A_{BB}\) is similar to \(A_{DD}\).
            
        \end{theorem}
        \pagebreak
        \vphantom
        \\
        \\
        We now define some important concepts.
        \begin{definition}{\Stop\,\,Kernel}{kernel}

            The kernel of a linear transformation \(L:V\to W\), is given by
            \begin{equation*}
                \ker(L)=\{\vec{v}\in V:L(\vec{v})=\vec{0}\}.
            \end{equation*}
            
        \end{definition}
        \begin{definition}{\Stop\,\,Range}{range}

            The range of a linear transformation \(L:V\to W\), is given by
            \begin{equation*}
                \range(L)=\{\vec{w}\in W:\exists\vec{v}\in V, L(\vec{v})=\vec{w}\}.
            \end{equation*}
            
        \end{definition}
        \vphantom
        \\
        \\
        Consider the following definition.
        \begin{theorem}{\Stop\,\,Kernel and Range are Subspaces}{kerransubspc}

            Let \(L:V\to W\) be a linear transformation. Then, \(\ker(L)\) is a subspace of \(V\) and \(\range(L)\) is a subspace of \(W\).
            \begin{proof}
                For \(\ker(L)\), we have \(\vec{0}_V\in\ker(L)\) since \(L(\vec{0}_V)=\vec{0}_W\). Then, for \(\vec{v}_1,\vec{v}_2\in \ker(L)\), we have
                \begin{align*}
                    L(\vec{v}_1+\vec{v}_2)&=L(\vec{v}_1)+L(\vec{v}_2) \\
                    &=\vec{0}_W+\vec{0}_W \\
                    &=\vec{0}_W,
                \end{align*}
                so \(\vec{v}_1+\vec{v}_2\in\ker(L)\). Then, we also have
                \begin{align*}
                    L(c\vec{v}_1)&=cL(\vec{v}_1) \\
                    &=c\vec{0}_W \\
                    &=\vec{0}_W,
                \end{align*}
                for some \(c\in\mathbb{F}\). Thus, \(c\vec{v}_1\in\ker(L)\), as desired. For \(\range(L)\), we have \(\vec{0}_W\in\range(L)\) since \(L(\vec{0}_V)=\vec{0}_W\). Then, if \(\vec{w}_1,\vec{w}_2\in\range(L)\), \(L(\vec{v}_1)=\vec{w}_1\) and \(L(\vec{v}_2)=\vec{w}_2\) for some \(\vec{v}_1,\vec{v}_2\in V\). Then,
                \begin{align*}
                    L(\vec{v}_1+\vec{v}_2)&=L(\vec{v}_1)+L(\vec{v}_2) \\
                    &=\vec{w}_1+\vec{w}_2,
                \end{align*}
                meaning \(\vec{w}_1+\vec{w}_2\in \range(L)\). Then, we also have
                \begin{align*}
                    L(c\vec{v}_1)&=cL(\vec{v}_1) \\
                    &=c\vec{w}
                \end{align*}
                for some \(c\in\mathbb{F}\). Thus, \(c\vec{w}\in\range(L)\), as desired.
            \end{proof}
            
        \end{theorem}

\pagebreak

\section{Lecture 33: November 11, 2022}

    \subsection{Finding the Kernel and the Range}

        Consider the linear transformation
        \begin{equation*}
            L_A:\mathbb{R}^n\to\mathbb{R}^m, \vec{v}\mapsto A\vec{v}.
        \end{equation*}
        Now, we want to find \(\ker(L_A)\) and \(\range(L_A)\). Consider the following theorem.
        \begin{theorem}{\Stop\,\,Finding the Kernel of a Linear Transformation}{findker}

            Let \(L_A\) be a linear transformation with
            \begin{equation*}
                L_A:\mathbb{R}^n\to\mathbb{R}^m, \vec{v}\mapsto A\vec{v}.
            \end{equation*}
            To find \(\ker(L)\), we need to find the solution set to \([A|\vec{0}]\), as 
            \begin{equation*}
                \ker(L)=\{\vec{v}\in V: A\vec{v}=\vec{0}\}.
            \end{equation*}
            We find a basis of \(\ker(L)\) by setting each free variable to \(1\) and the others to \(0\). Then, \(\dim(\ker(L))\) is the number of free variables in the solution set.

        \end{theorem}
        \vphantom
        \\
        \\
        We remark that, in general, \(\dim(\ker(L))\) is the number of free variables in the homogeneous solution set. Consider the following theorem.
        \begin{theorem}{\Stop\,\,Finding the Range of a Linear Transformation}{findrange}

            Let \(L_A\) be a linear transformation with
            \begin{equation*}
                L_A:\mathbb{R}^n\to\mathbb{R}^m, \vec{v}\mapsto A\vec{v}.
            \end{equation*}
            To find \(\range(L)\), we need to row reduce \(A\). The pivot columns form a basis of the range. Then, \(\dim(\range(L))=\rank A\), the number of pivots.

        \end{theorem}
        \pagebreak
        \vphantom
        \\
        \\
        The next theorems combine the results of Theorem \ref{thm:findker} and Theorem \ref{thm:findrange} to find \(\dim(\ker(L))+\dim(\range(L))\), culminating in Theorem \ref{thm:dimthm}.
        \begin{theorem}{\Stop\,\,The Dimension Theorem, in \(\mathbb{R}^n\)}{dimthmrn}

            Let \(L_A\) be a linear transformation with
            \begin{equation*}
                L_A:\mathbb{R}^n\to\mathbb{R}^m, \vec{v}\mapsto A\vec{v}.
            \end{equation*}
            Then,
            \begin{enumerate}
                \item \(\dim(\range(L))=\rank A\).
                \item \(\dim(\ker(L))=n-\rank A\).
                \item \(\dim(\ker(L))+\dim(\range(L))=n\).
            \end{enumerate}
            
        \end{theorem}
        \begin{theorem}{\Stop\,\,The Dimension Theorem}{dimthm}

            Suppose \(V\) and \(W\) are finite dimensional vector spaces and \(L:V\to W\) is a linear transformation. Then,
            \begin{equation*}
                \dim(\ker(L))+\dim(\range(L))=\dim V.
            \end{equation*}
            
        \end{theorem}

    \pagebreak

    \subsection{Injections, Surjections, Bijections, and Isomorphisms}

        We state two theorems about if linear transformations are injective or surjective.
        \begin{theorem}{\Stop\,\,Determining Injectivity and Surjectivity}{detinjsurj}

            Suppose \(V\) and \(W\) are finite dimensional vector spaces and \(L:V\to W\) is a linear transformation. Then,
            \begin{enumerate}
                \item The linear transformation \(L\) is injective if and only if \(\ker(L)=\{\vec{0}_V\}\).
                \begin{proof}
                    Suppose \(L\) is injective and let \(\vec{v}\in\ker(L)\). Now, \(L(\vec{v})=\vec{0}_W\). Similarly, \(L(\vec{0}_V)=\vec{0}_W\), and since \(L\) is injective, \(\vec{v}=\vec{0}_V\). Now, we suppose \(\ker(L)=\{\vec{0}_V\}\). We must show \(L\) is injective. Let \(\vec{v}_1,\vec{v}_2\in V\) with \(L(\vec{v}_1)=L(\vec{v}_2)\). We wish to show \(\vec{v}_1=\vec{v}_2\). Now, we have \(L(\vec{v}_1)-L(\vec{v}_2)=\vec{0}_W\), implying that \(L(\vec{v}_1-\vec{v}_2)=\vec{0}_W\). Thus, \(\vec{v}_1-\vec{v}_2\in\ker(L)\). Since \(\ker(L)=\{\vec{0}_V\}\), \(\vec{v}_1-\vec{v}_2=\vec{0}_V\), and so, \(\vec{v}_1=\vec{v}_2\), as desired.
                \end{proof}
                \item The linear transformation \(L\) is surjective if and only if \(\dim(\range(L))=\dim W\).
                \begin{proof}
                    By definition, \(L\) is surjective if and only if \(\range(L)=W\). Then, since \(\range(L)\) is a subspace of \(W\), \(\range(L)=W\) if and only if \(\dim(\range(L))=\dim W\) by Theorem \ref{thm:dimsubspc}.
                \end{proof}
            \end{enumerate}
            
        \end{theorem}
        \vphantom
        \\
        \\
        Consider the following definition.
        \begin{definition}{\Stop\,\,Isomorphisms}{isomorphisms}

            Suppose \(V\) and \(W\) are finite dimensional vector spaces and \(L:V\to W\) is a linear transformation; \(L\) an isomorphism from \(V\) to \(W\) if and only if \(L\) is both injective and surjective, or bijective.
            
        \end{definition}
        \begin{definition}{\Stop\,\,Invertible Linear Transformations}{invtrans}

            Suppose \(V\) and \(W\) are finite dimensional vector spaces and \(L:V\to W\) is a linear transformation. Then, \(L\) is an invertible linear transformation if and only if there exists some function \(M:W\to V\) such that
            \begin{equation*}
                (M\circ L)(\vec{v})=\vec{v}
            \end{equation*}
            for all \(\vec{v}\in V\) and
            \begin{equation*}
                (L\circ M)(\vec{w})=\vec{w}
            \end{equation*}
            for all \(\vec{w}\in W\).
            
        \end{definition}
        \pagebreak
        \vphantom
        \\
        \\
        \begin{theorem}{\Stop\,\,Isomorphism If And Only If Invertible}{isoinv}
            \DOTHISLATER
        \end{theorem}
        \vphantom
        \\
        \\
        \DOTHISLATER
        